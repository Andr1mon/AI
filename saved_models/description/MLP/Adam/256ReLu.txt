Model: MLP
Optimizer: Adam
Optimizer Learning rate: 0.001
Input layer: board_size*board_size [8*8]
Hidden layer: ReLU 256
Output layer: board_size*board_size [8*8]
Dropout layer: 0.1
Epoch: 200
Earlystopping: 20
Number of parameters: 33088
Time: 1155
The best score on DEV 164: 25.64%